# ğŸ­ Reconhecimento Facial - DetecÃ§Ã£o de ExpressÃµes em VÃ­deo

Sistema de anÃ¡lise de expressÃµes faciais e emoÃ§Ãµes em vÃ­deos utilizando Deep Learning. O projeto processa vÃ­deos frame a frame, detecta faces e identifica as emoÃ§Ãµes dominantes, gerando um vÃ­deo de saÃ­da com anotaÃ§Ãµes visuais.

## ğŸ“‹ Ãndice

- [Funcionalidades](#-funcionalidades)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Como Usar](#-como-usar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Exemplos](#-exemplos)
- [Troubleshooting](#-troubleshooting)
- [Contribuindo](#-contribuindo)
- [LicenÃ§a](#-licenÃ§a)

## âœ¨ Funcionalidades

- âœ… DetecÃ§Ã£o de mÃºltiplas faces em vÃ­deos
- âœ… AnÃ¡lise de emoÃ§Ãµes em tempo real (felicidade, tristeza, raiva, surpresa, medo, nojo, neutro)
- âœ… GeraÃ§Ã£o de vÃ­deo de saÃ­da com anotaÃ§Ãµes visuais
- âœ… Barra de progresso para acompanhamento do processamento
- âœ… Suporte a visualizaÃ§Ã£o em tempo real (opcional)
- âœ… Processamento frame a frame com alta precisÃ£o

## ğŸ”§ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter instalado:

- **Python 3.8+** (recomendado: Python 3.10 ou superior)
- **pip** (gerenciador de pacotes Python)
- **Git** (opcional, para clonar o repositÃ³rio)

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio (ou baixe os arquivos)

```bash
git clone <url-do-repositorio>
cd reconhecimento-facial
```

### 2. Crie um ambiente virtual (recomendado)

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/macOS:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

> **Nota:** A primeira execuÃ§Ã£o pode demorar mais tempo, pois o DeepFace baixarÃ¡ os modelos de deep learning necessÃ¡rios automaticamente.

## ğŸš€ Como Usar

### Uso BÃ¡sico

1. Coloque seu vÃ­deo de entrada na pasta `videos/` com o nome `input_video.mp4`

2. Execute o script:

```bash
python detect-expression-video.py
```

3. O vÃ­deo processado serÃ¡ salvo em `videos/output_video.mp4`

### Uso ProgramÃ¡tico

VocÃª tambÃ©m pode usar a funÃ§Ã£o diretamente no seu cÃ³digo:

```python
from detect-expression-video import detect_expressions_in_video

# Processar vÃ­deo e salvar resultado
detect_expressions_in_video(
    video_path="caminho/para/video.mp4",
    output_path="caminho/para/saida.mp4",
    display=False  # True para visualizar em tempo real
)
```

### ParÃ¢metros da FunÃ§Ã£o

- `video_path` (str): Caminho para o vÃ­deo de entrada
- `output_path` (str, opcional): Caminho para salvar o vÃ­deo processado. Se `None`, nÃ£o salva o vÃ­deo
- `display` (bool, opcional): Se `True`, exibe o vÃ­deo em tempo real durante o processamento (pressione 'q' para sair)

## ğŸ“ Estrutura do Projeto

```
reconhecimento-facial/
â”‚
â”œâ”€â”€ detect-expression-video.py  # Script principal
â”œâ”€â”€ requirements.txt            # DependÃªncias do projeto
â”œâ”€â”€ README.md                   # Este arquivo
â”œâ”€â”€ .gitignore                  # Arquivos ignorados pelo Git
â”‚
â””â”€â”€ videos/                     # Pasta para vÃ­deos
    â”œâ”€â”€ input_video.mp4         # VÃ­deo de entrada (nÃ£o versionado)
    â””â”€â”€ output_video.mp4        # VÃ­deo de saÃ­da (nÃ£o versionado)
```

## ğŸ›  Tecnologias Utilizadas

- **[OpenCV](https://opencv.org/)** - Processamento de vÃ­deo e imagens
- **[DeepFace](https://github.com/serengil/deepface)** - Reconhecimento facial e anÃ¡lise de emoÃ§Ãµes
- **[TensorFlow](https://www.tensorflow.org/)** - Framework de deep learning
- **[NumPy](https://numpy.org/)** - ComputaÃ§Ã£o numÃ©rica
- **[tqdm](https://github.com/tqdm/tqdm)** - Barra de progresso

## ğŸ“ Exemplos

### Exemplo 1: Processamento bÃ¡sico

```python
python detect-expression-video.py
```

### Exemplo 2: VisualizaÃ§Ã£o em tempo real

```python
from detect-expression-video import detect_expressions_in_video

detect_expressions_in_video(
    video_path="videos/input_video.mp4",
    output_path=None,
    display=True  # Visualiza o vÃ­deo em tempo real
)
```

### Exemplo 3: Processar vÃ­deo customizado

```python
from detect-expression-video import detect_expressions_in_video

detect_expressions_in_video(
    video_path="meu_video.mp4",
    output_path="resultado.mp4",
    display=False
)
```

## ğŸ” Troubleshooting

### Erro: "Could not open video"
- Verifique se o caminho do vÃ­deo estÃ¡ correto
- Certifique-se de que o arquivo de vÃ­deo existe e nÃ£o estÃ¡ corrompido
- Verifique se o formato do vÃ­deo Ã© suportado (MP4, AVI, MOV, etc.)

### Erro: "ModuleNotFoundError"
- Certifique-se de que todas as dependÃªncias foram instaladas: `pip install -r requirements.txt`
- Verifique se o ambiente virtual estÃ¡ ativado

### Processamento muito lento
- O processamento depende do tamanho do vÃ­deo e do hardware
- Para vÃ­deos grandes, considere reduzir a resoluÃ§Ã£o ou usar um backend de detecÃ§Ã£o mais rÃ¡pido
- O primeiro uso Ã© mais lento devido ao download dos modelos

### Erro relacionado ao TensorFlow
- Certifique-se de ter uma versÃ£o compatÃ­vel do TensorFlow instalada
- Em alguns sistemas, pode ser necessÃ¡rio instalar dependÃªncias adicionais do sistema

### Modelos nÃ£o sÃ£o baixados
- Verifique sua conexÃ£o com a internet
- Os modelos sÃ£o baixados automaticamente na primeira execuÃ§Ã£o
- Os modelos sÃ£o salvos em `.deepface/` na pasta do usuÃ¡rio

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:

1. Fazer um fork do projeto
2. Criar uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abrir um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¤ Autor

Desenvolvido como parte do curso de PÃ³s-GraduaÃ§Ã£o em IA da FIAP.

---

â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela no repositÃ³rio!

