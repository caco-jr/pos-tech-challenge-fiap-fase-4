# üé≠ Reconhecimento Facial - Detec√ß√£o de Express√µes em V√≠deo

Sistema de an√°lise de express√µes faciais e emo√ß√µes em v√≠deos utilizando Deep Learning. O projeto processa v√≠deos frame a frame, detecta faces e identifica as emo√ß√µes dominantes, gerando um v√≠deo de sa√≠da com anota√ß√µes visuais.

## üìã √çndice

- [Funcionalidades](#-funcionalidades)
- [Pr√©-requisitos](#-pr√©-requisitos)
- [Instala√ß√£o](#-instala√ß√£o)
- [Como Usar](#-como-usar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [Exemplos](#-exemplos)
- [Troubleshooting](#-troubleshooting)
- [Contribuindo](#-contribuindo)
- [Licen√ßa](#-licen√ßa)

## ‚ú® Funcionalidades

- ‚úÖ **Reconhecimento facial**: Detec√ß√£o de m√∫ltiplas faces em v√≠deos
- ‚úÖ **An√°lise de express√µes emocionais**: An√°lise de emo√ß√µes em tempo real (felicidade, tristeza, raiva, surpresa, medo, nojo, neutro)
- ‚úÖ **Detec√ß√£o de atividades**: Categoriza√ß√£o autom√°tica de atividades baseada em movimento e padr√µes comportamentais
- ‚úÖ **Detec√ß√£o de anomalias**: Identifica√ß√£o de movimentos bruscos e comportamentos at√≠picos
- ‚úÖ **Gera√ß√£o de relat√≥rio**: Cria√ß√£o autom√°tica de relat√≥rio com estat√≠sticas completas da an√°lise
- ‚úÖ Gera√ß√£o de v√≠deo de sa√≠da com anota√ß√µes visuais
- ‚úÖ Barra de progresso para acompanhamento do processamento
- ‚úÖ Suporte a visualiza√ß√£o em tempo real (opcional)
- ‚úÖ Processamento frame a frame com alta precis√£o

## üîß Pr√©-requisitos

Antes de come√ßar, certifique-se de ter instalado:

- **Python 3.8 at√© 3.12** (recomendado: Python 3.12 como vers√£o m√°xima ideal)
- **[UV](https://github.com/astral-sh/uv)** (recomendado) - Gerenciador r√°pido de vers√µes Python e pacotes
- **pip** (alternativa, se n√£o usar UV)
- **Git** (opcional, para clonar o reposit√≥rio)

## üì¶ Instala√ß√£o

### 1. Clone o reposit√≥rio (ou baixe os arquivos)

```bash
git clone <url-do-repositorio>
cd reconhecimento-facial
```

### 2. Instale o UV (Recomendado)

O UV √© uma ferramenta moderna e extremamente r√°pida para gerenciar vers√µes do Python e instalar pacotes. √â altamente recomendado para uma melhor experi√™ncia de desenvolvimento.

**Windows (PowerShell):**

```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

**Linux/macOS:**

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Ap√≥s a instala√ß√£o, reinicie o terminal ou adicione o UV ao PATH.

### 3. Configure o ambiente com UV

O UV gerencia automaticamente a vers√£o do Python e cria o ambiente virtual:

```bash
# Instala Python 3.12 (se necess√°rio) e cria o ambiente virtual
uv venv

# Ativa o ambiente virtual
# Windows:
.venv\Scripts\activate
# Linux/macOS:
source .venv/bin/activate

# Instala as depend√™ncias
uv pip install -r requirements.txt
```

Ou, de forma ainda mais simples, o UV pode instalar tudo de uma vez:

```bash
# Cria o ambiente e instala as depend√™ncias automaticamente
uv venv --python 3.12
uv pip install -r requirements.txt
```

### Instala√ß√£o Alternativa (sem UV)

Se preferir usar o m√©todo tradicional:

**Windows:**

```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

**Linux/macOS:**

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

> **Nota:** A primeira execu√ß√£o pode demorar mais tempo, pois o DeepFace baixar√° os modelos de deep learning necess√°rios automaticamente.

## üöÄ Como Usar

### Uso B√°sico

1. **Baixe o v√≠deo de entrada:**
   - Acesse o [Google Drive](https://drive.google.com/drive/folders/11NGeYVnSvDF0bo3NHS47fb4b7vqkpALp)
   - Baixe o v√≠deo: `Unlocking Facial Recognition_ Diverse Activities Analysis.mp4`
   - **Importante:** Renomeie o arquivo para `input_video.mp4`
   - Coloque o arquivo renomeado na pasta `videos/`

2. Execute o script:

```bash
python detect-expression-video.py
```

3. O v√≠deo processado ser√° salvo em `videos/output_video.mp4`

4. O relat√≥rio de an√°lise ser√° salvo em `relatorio_analise.txt` na raiz do projeto

### Uso Program√°tico

Voc√™ tamb√©m pode usar a fun√ß√£o diretamente no seu c√≥digo:

```python
from detect-expression-video import detect_expressions_in_video

# Processar v√≠deo e salvar resultado
success, summary = detect_expressions_in_video(
    video_path="caminho/para/video.mp4",
    output_path="caminho/para/saida.mp4",
    display=False,  # True para visualizar em tempo real
    report_path="relatorio.txt"  # Caminho para salvar o relat√≥rio
)

if success:
    print(f"Frames analisados: {summary['total_frames_analisados']}")
    print(f"Anomalias detectadas: {summary['numero_anomalias_detectadas']}")
```

### Par√¢metros da Fun√ß√£o

- `video_path` (str): Caminho para o v√≠deo de entrada
- `output_path` (str, opcional): Caminho para salvar o v√≠deo processado. Se `None`, n√£o salva o v√≠deo
- `display` (bool, opcional): Se `True`, exibe o v√≠deo em tempo real durante o processamento (pressione 'q' para sair)
- `report_path` (str, opcional): Caminho para salvar o relat√≥rio de an√°lise. Se `None`, o relat√≥rio ser√° exibido no console

### Retorno da Fun√ß√£o

A fun√ß√£o retorna uma tupla `(success, summary)` onde:

- `success` (bool): `True` se o processamento foi conclu√≠do com sucesso
- `summary` (dict): Dicion√°rio com estat√≠sticas completas da an√°lise, incluindo:
  - `total_frames_analisados`: Total de frames processados
  - `total_faces_detectadas`: Total de faces detectadas
  - `numero_anomalias_detectadas`: N√∫mero de anomalias encontradas
  - `atividades_detectadas`: N√∫mero de atividades categorizadas
  - `emocoes_detectadas`: Distribui√ß√£o de emo√ß√µes detectadas
  - E muito mais...

## üìÅ Estrutura do Projeto

```
reconhecimento-facial/
‚îÇ
‚îú‚îÄ‚îÄ detect-expression-video.py  # Script principal
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ README.md                   # Este arquivo
‚îú‚îÄ‚îÄ .gitignore                  # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ relatorio_analise.txt       # Relat√≥rio gerado automaticamente (n√£o versionado)
‚îÇ
‚îî‚îÄ‚îÄ videos/                     # Pasta para v√≠deos
    ‚îú‚îÄ‚îÄ input_video.mp4         # V√≠deo de entrada (n√£o versionado)
    ‚îî‚îÄ‚îÄ output_video.mp4        # V√≠deo de sa√≠da (n√£o versionado)
```

## üõ† Tecnologias Utilizadas

- **[OpenCV](https://opencv.org/)** - Processamento de v√≠deo e imagens
- **[DeepFace](https://github.com/serengil/deepface)** - Reconhecimento facial e an√°lise de emo√ß√µes
- **[TensorFlow](https://www.tensorflow.org/)** - Framework de deep learning
- **[NumPy](https://numpy.org/)** - Computa√ß√£o num√©rica
- **[tqdm](https://github.com/tqdm/tqdm)** - Barra de progresso

## üìù Exemplos

### Exemplo 1: Processamento b√°sico

```python
python detect-expression-video.py
```

Isso ir√°:

- Processar o v√≠deo `videos/input_video.mp4`
- Gerar o v√≠deo processado em `videos/output_video.mp4`
- Criar o relat√≥rio em `relatorio_analise.txt`

### Exemplo 2: Visualiza√ß√£o em tempo real

```python
from detect-expression-video import detect_expressions_in_video

success, summary = detect_expressions_in_video(
    video_path="videos/input_video.mp4",
    output_path=None,
    display=True,  # Visualiza o v√≠deo em tempo real
    report_path="meu_relatorio.txt"
)

print(f"Anomalias encontradas: {summary['numero_anomalias_detectadas']}")
```

### Exemplo 3: Processar v√≠deo customizado

```python
from detect-expression-video import detect_expressions_in_video

success, summary = detect_expressions_in_video(
    video_path="meu_video.mp4",
    output_path="resultado.mp4",
    display=False,
    report_path="analise_completa.txt"
)

# Acessar estat√≠sticas detalhadas
print(f"Total de frames: {summary['total_frames_analisados']}")
print(f"Atividades detectadas: {summary['atividades_detectadas']}")
print(f"Emo√ß√£o mais frequente: {summary['emocao_mais_frequente']}")
```

## üìä Relat√≥rio de An√°lise

O sistema gera automaticamente um relat√≥rio completo contendo:

- **Resumo Geral**: Total de frames analisados, faces detectadas e anomalias
- **An√°lise de Emo√ß√µes**: Distribui√ß√£o percentual de todas as emo√ß√µes detectadas
- **An√°lise de Atividades**: Categoriza√ß√£o e contagem de atividades identificadas
- **Detec√ß√£o de Anomalias**: Lista detalhada de movimentos bruscos e comportamentos at√≠picos

O relat√≥rio √© salvo em formato de texto e pode ser facilmente compartilhado ou inclu√≠do na documenta√ß√£o do projeto.

## üîç Troubleshooting

### Erro: "Could not open video"

- Verifique se o caminho do v√≠deo est√° correto
- Certifique-se de que o arquivo de v√≠deo existe e n√£o est√° corrompido
- Verifique se o formato do v√≠deo √© suportado (MP4, AVI, MOV, etc.)

### Erro: "ModuleNotFoundError"

- Certifique-se de que todas as depend√™ncias foram instaladas:
  - Com UV: `uv pip install -r requirements.txt`
  - Sem UV: `pip install -r requirements.txt`
- Verifique se o ambiente virtual est√° ativado
- Se estiver usando UV, certifique-se de que o Python 3.12 (ou vers√£o compat√≠vel) est√° instalado: `uv python install 3.12`

### Processamento muito lento

- O processamento depende do tamanho do v√≠deo e do hardware
- Para v√≠deos grandes, considere reduzir a resolu√ß√£o ou usar um backend de detec√ß√£o mais r√°pido
- O primeiro uso √© mais lento devido ao download dos modelos

### Erro relacionado ao TensorFlow

- Certifique-se de ter uma vers√£o compat√≠vel do TensorFlow instalada
- Em alguns sistemas, pode ser necess√°rio instalar depend√™ncias adicionais do sistema

### Modelos n√£o s√£o baixados

- Verifique sua conex√£o com a internet
- Os modelos s√£o baixados automaticamente na primeira execu√ß√£o
- Os modelos s√£o salvos em `.deepface/` na pasta do usu√°rio

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para:

1. Fazer um fork do projeto
2. Criar uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abrir um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

## üë§ Autor

Desenvolvido como parte do curso de P√≥s-Gradua√ß√£o em IA da FIAP.

---

‚≠ê Se este projeto foi √∫til para voc√™, considere dar uma estrela no reposit√≥rio!
